# -----------------------------
# Training configuration
# -----------------------------
model: "gemma2"
world_size: 4
force: False
train-tokenizer: False
model_info: True

inference: False
max_new_tokens: 64
prompt: "merhaba"
checkpoint: "./output/gemma2/gemma2_best_model.pt"
pre_training_hf_data: "canbingol/vngrs-web-corpus-200k"
it_hf_data: "merve/turkish_instructions"
text_column_name: "text"
saved_token_path: "./data/pretrain/default_tokenizer"
hf_tokenzier: "vngrs-ai/Kumru-2B"

epoch: 1
training_steps: None
lr: 1e-3
eval-steps: 100
eval_sample: 10
vocab_size: 50176
batch_size: 60
max_seq_len: 256
shuffle: False
drop_last: True
num_workers: 0
pin_memory: True
