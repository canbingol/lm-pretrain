# -----------------------------
# Training configuration
# -----------------------------
model: "qwen3"
world_size: 1
force: False
train-tokenizer: False
model_info: True

inference: False
max_new_tokens: 64
prompt: "merhaba"
checkpoint: "./output/gpt2/GPT2_best_model_data500k_loss4.3.pt"
pre_training_hf_data: "canbingol/vngrs-web-corpus-500k"
it_hf_data: "canbingol/turkish_instructions"
text_column_name: "text"
saved_token_path: "./data/pretrain/default_tokenizer"
hf_tokenizer: "vngrs-ai/Kumru-2B"

epoch: 5
training_steps: None
lr: 1e-4
eval-steps: 10
eval_sample: 1
vocab_size: 50176
batch_size: 1
max_seq_len: 256
shuffle: False
drop_last: True
num_workers: 0
pin_memory: True
